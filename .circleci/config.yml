version: 2.1

commands:
  install_deps:
    description: "Steps for installing deps with caching enabled"
    steps:
      - run:
          name: Generate date for cache key
          command: date +%F > .circleci-date
      - restore_cache:
          key: env-v7-{{ arch }}-{{ checksum ".circleci/setup_env.sh" }}-{{ checksum "Makefile" }}-{{ checksum ".circleci-date" }}-{{ checksum "requirements.txt" }}
      - run:
          name: Install libs
          command: |
            source .circleci/setup_env.sh
      - run:
          name: Install TorchBenchmark
          command: |
            FILE=torchbenchmark/env-v7.key
            if test -f "$FILE"; then
              # If torchbenchmark is updated, we need to invalidate the cache by bumping up the key version number,
              # but this won't happen very often because we also update cache daily.
              echo "$FILE exists means restore_cache has succeeded, so skip installing torchbenchmark."
            else
              source .circleci/setup_env.sh
              conda install -y -c conda-forge git-lfs
              git lfs install --skip-repo --skip-smudge
              rm -rf torchbenchmark
              git clone --recursive git@github.com:pytorch/benchmark.git torchbenchmark
              cd torchbenchmark
              # Pin to specific version to avoid upstream breakages
              git checkout 24b95f2f627bf07a61cefed653419389a7586357
              python install.py
              pip install gym==0.25.2  # workaround issue in 0.26.0
              touch env-v7.key
              cd ..
              make setup_nightly_gpu
            fi
      - run:
          name: Install Huggingface
          command: |
            source .circleci/setup_env.sh
            python -m pip install git+https://github.com/huggingface/transformers.git#egg=transformers
      - run:
          name: Install TIMM
          command: |
            source .circleci/setup_env.sh
            python -m pip install git+https://github.com/rwightman/pytorch-image-models
      - save_cache:
          key: env-v7-{{ arch }}-{{ checksum ".circleci/setup_env.sh" }}-{{ checksum "Makefile" }}-{{ checksum ".circleci-date" }}-{{ checksum "requirements.txt" }}
          paths:
            - conda
            - env
            - torchbenchmark

jobs:
  unit_test:
    machine:
      # https://circleci.com/docs/2.0/configuration-reference/#available-linux-gpu-images
      image: ubuntu-2004-cuda-11.4:202110-01
    resource_class: gpu.nvidia.large
    steps:
      - checkout
      - install_deps
      - run:
          name: Tests
          command: |
            source .circleci/setup_env.sh
            make develop
            mkdir test-results
            python tools/verify_install.py
            pytest -v --junitxml=test-results/junit.xml -k "cuda and not TestInductorOpInfoCPU"
      - store_test_results:
          path: test-results

  coverage:
    machine:
      image: ubuntu-2004-cuda-11.4:202110-01
    resource_class: gpu.nvidia.large
    steps:
      - checkout
      - install_deps
      - run:
          name: TorchBench Coverage run
          command: |
            source .circleci/setup_env.sh
            make develop
            python benchmarks/torchbench.py --performance --coverage -d cuda -x Super_SloMo -x moco -x pytorch_struct -x fastNLP_Bert
      - store_artifacts:
          path: coverage.csv
      - run:
          name: TorchBench coverage
          command: |
            source .circleci/setup_env.sh
            python .circleci/check_coverage.py

  aot_eager_torchbench_inference:
    machine:
      image: ubuntu-2004-cuda-11.4:202110-01
    resource_class: gpu.nvidia.large
    steps:
      - checkout
      - install_deps
      - run:
          name: TorchBench AotAutograd Eager inference run
          command: |
            source .circleci/setup_env.sh
            make develop
            python benchmarks/torchbench.py --accuracy --ci --backend=aot_eager -d cuda --output=aot_eager_torchbench_inference.csv
      - store_artifacts:
          path: aot_eager_torchbench_inference.csv
      - run:
          name: TorchBench AotAutograd Eager inference result check
          command: |
            source .circleci/setup_env.sh
            python .circleci/check_csv.py -f aot_eager_torchbench_inference.csv

  aot_eager_hf_inference:
    machine:
      image: ubuntu-2004-cuda-11.4:202110-01
    resource_class: gpu.nvidia.large
    steps:
      - checkout
      - install_deps
      - run:
          name: Huggingface AotAutograd Eager inference run
          command: |
            source .circleci/setup_env.sh
            make develop
            python benchmarks/huggingface.py --accuracy --ci --backend=aot_eager -d cuda --output=aot_eager_hf_inference.csv
      - store_artifacts:
          path: aot_eager_hf_inference.csv
      - run:
          name: Huggingface AotAutograd Eager inference result check
          command: |
            source .circleci/setup_env.sh
            python .circleci/check_csv.py -f aot_eager_hf_inference.csv

  aot_eager_timm_inference:
    machine:
      image: ubuntu-2004-cuda-11.4:202110-01
    resource_class: gpu.nvidia.large
    steps:
      - checkout
      - install_deps
      - run:
          name: TIMM AotAutograd Eager inference run
          command: |
            source .circleci/setup_env.sh
            make develop
            python benchmarks/timm_models.py --accuracy --ci --backend=aot_eager -d cuda --output=aot_eager_timm_inference.csv
      - store_artifacts:
          path: aot_eager_timm_inference.csv
      - run:
          name: TIMM AotAutograd Eager inference result check
          command: |
            source .circleci/setup_env.sh
            python .circleci/check_csv.py -f aot_eager_timm_inference.csv

  aot_eager_torchbench_training:
    machine:
      image: ubuntu-2004-cuda-11.4:202110-01
    resource_class: gpu.nvidia.large
    steps:
      - checkout
      - install_deps
      - run:
          name: TorchBench AotAutograd Eager training run
          command: |
            source .circleci/setup_env.sh
            make develop
            python benchmarks/torchbench.py --accuracy --ci --training --amp --backend=aot_eager -d cuda --output=aot_eager_torchbench_training.csv
      - store_artifacts:
          path: aot_eager_torchbench_training.csv
      - run:
          name: TorchBench AotAutograd Eager training result check
          command: |
            source .circleci/setup_env.sh
            python .circleci/check_csv.py -f aot_eager_torchbench_training.csv

  aot_eager_hf_training:
    machine:
      image: ubuntu-2004-cuda-11.4:202110-01
    resource_class: gpu.nvidia.large
    steps:
      - checkout
      - install_deps
      - run:
          name: Huggingface AotAutograd Eager training run
          command: |
            source .circleci/setup_env.sh
            make develop
            python benchmarks/huggingface.py --accuracy --ci --training --amp --backend=aot_eager -d cuda --output=aot_eager_hf_training.csv
      - store_artifacts:
          path: aot_eager_hf_training.csv
      - run:
          name: Huggingface AotAutograd Eager training result check
          command: |
            source .circleci/setup_env.sh
            python .circleci/check_csv.py -f aot_eager_hf_training.csv

  aot_eager_timm_training:
    machine:
      image: ubuntu-2004-cuda-11.4:202110-01
    resource_class: gpu.nvidia.large
    steps:
      - checkout
      - install_deps
      - run:
          name: TIMM AotAutograd Eager training run
          command: |
            source .circleci/setup_env.sh
            make develop
            python benchmarks/timm_models.py --accuracy --ci --training --amp --backend=aot_eager -d cuda --output=aot_eager_timm_training.csv
      - store_artifacts:
          path: aot_eager_timm_training.csv
      - run:
          name: TIMM AotAutograd Eager training result check
          command: |
            source .circleci/setup_env.sh
            python .circleci/check_csv.py -f aot_eager_timm_training.csv

  inductor_torchbench_inference:
    machine:
      image: ubuntu-2004-cuda-11.4:202110-01
    resource_class: gpu.nvidia.large
    steps:
      - checkout
      - install_deps
      - run:
          name: TorchBench TorchInductor inference run
          command: |
            source .circleci/setup_env.sh
            make develop
            python benchmarks/torchbench.py --accuracy --ci -d cuda --inductor --float32 --output=inductor_torchbench_inference.csv
      - store_artifacts:
          path: inductor_torchbench_inference.csv
      - run:
          name: TorchBench inference result check
          command: |
            source .circleci/setup_env.sh
            python .circleci/check_csv.py -f inductor_torchbench_inference.csv

  inductor_torchbench_training_0:
    machine:
      image: ubuntu-2004-cuda-11.4:202110-01
    resource_class: gpu.nvidia.large
    steps:
      - checkout
      - install_deps
      - run:
          name: TorchBench TorchInductor training run
          command: |
            source .circleci/setup_env.sh
            make develop
            python benchmarks/torchbench.py --accuracy --ci --skip-accuracy-check -d cuda --inductor --training --float32 \
              --total-partitions 2 --partition-id 0 --output=inductor_torchbench_training_0.csv
      - store_artifacts:
          path: inductor_torchbench_training_0.csv
      - run:
          name: TorchBench training result check
          command: |
            source .circleci/setup_env.sh
            python .circleci/check_csv.py -f inductor_torchbench_training_0.csv

  inductor_torchbench_training_1:
    machine:
      image: ubuntu-2004-cuda-11.4:202110-01
    resource_class: gpu.nvidia.large
    steps:
      - checkout
      - install_deps
      - run:
          name: TorchBench TorchInductor training run
          command: |
            source .circleci/setup_env.sh
            make develop
            python benchmarks/torchbench.py --accuracy --ci --skip-accuracy-check -d cuda --inductor --training --float32 \
              --total-partitions 2 --partition-id 1 -x pytorch_CycleGAN_and_pix2pix --output=inductor_torchbench_training_1.csv
      - store_artifacts:
          path: inductor_torchbench_training_1.csv
      - run:
          name: TorchBench training result check
          command: |
            source .circleci/setup_env.sh
            python .circleci/check_csv.py -f inductor_torchbench_training_1.csv

  inductor_hf_inference_0:
    machine:
      image: ubuntu-2004-cuda-11.4:202110-01
    resource_class: gpu.nvidia.large
    steps:
      - checkout
      - install_deps
      - run:
          name: Huggingface TorchInductor inference run
          command: |
            source .circleci/setup_env.sh
            make develop
            python benchmarks/huggingface.py --accuracy --ci -d cuda --inductor --float32 \
              --total-partitions 2 --partition-id 0 --output=inductor_hf_inference_0.csv
      - store_artifacts:
          path: inductor_hf_inference_0.csv
      - run:
          name: Huggingface inference result check
          command: |
            source .circleci/setup_env.sh
            python .circleci/check_csv.py -f inductor_hf_inference_0.csv

  inductor_hf_inference_1:
    machine:
      image: ubuntu-2004-cuda-11.4:202110-01
    resource_class: gpu.nvidia.large
    steps:
      - checkout
      - install_deps
      - run:
          name: Huggingface TorchInductor inference run
          command: |
            source .circleci/setup_env.sh
            make develop
            python benchmarks/huggingface.py --accuracy --ci -d cuda --inductor --float32 \
              --total-partitions 2 --partition-id 1 --output=inductor_hf_inference_1.csv
      - store_artifacts:
          path: inductor_hf_inference_1.csv
      - run:
          name: Huggingface inference result check
          command: |
            source .circleci/setup_env.sh
            python .circleci/check_csv.py -f inductor_hf_inference_1.csv

  inductor_hf_training_0:
    machine:
      image: ubuntu-2004-cuda-11.4:202110-01
    resource_class: gpu.nvidia.large
    steps:
      - checkout
      - install_deps
      - run:
          name: Huggingface TorchInductor training run
          command: |
            source .circleci/setup_env.sh
            make develop
            python benchmarks/huggingface.py --accuracy --ci -d cuda --inductor --float32 --training \
              --total-partitions 3 --partition-id 0 --output=inductor_hf_training_0.csv
      - store_artifacts:
          path: inductor_hf_training_0.csv
      - run:
          name: Huggingface training result check
          command: |
            source .circleci/setup_env.sh
            python .circleci/check_csv.py -f inductor_hf_training_0.csv

  inductor_hf_training_1:
    machine:
      image: ubuntu-2004-cuda-11.4:202110-01
    resource_class: gpu.nvidia.large
    steps:
      - checkout
      - install_deps
      - run:
          name: Huggingface TorchInductor training run
          command: |
            source .circleci/setup_env.sh
            make develop
            python benchmarks/huggingface.py --accuracy --ci -d cuda --inductor --float32 --training \
              --total-partitions 3 --partition-id 1 --output=inductor_hf_training_1.csv
      - store_artifacts:
          path: inductor_hf_training_1.csv
      - run:
          name: Huggingface training result check
          command: |
            source .circleci/setup_env.sh
            python .circleci/check_csv.py -f inductor_hf_training_1.csv

  inductor_hf_training_2:
    machine:
      image: ubuntu-2004-cuda-11.4:202110-01
    resource_class: gpu.nvidia.large
    steps:
      - checkout
      - install_deps
      - run:
          name: Huggingface TorchInductor training run
          command: |
            source .circleci/setup_env.sh
            make develop
            python benchmarks/huggingface.py --accuracy --ci -d cuda --inductor --float32 --training \
              --total-partitions 3 --partition-id 2 --output=inductor_hf_training_2.csv
      - store_artifacts:
          path: inductor_hf_training_2.csv
      - run:
          name: Huggingface training result check
          command: |
            source .circleci/setup_env.sh
            python .circleci/check_csv.py -f inductor_hf_training_2.csv

  inductor_timm_inference_0:
    machine:
      image: ubuntu-2004-cuda-11.4:202110-01
    resource_class: gpu.nvidia.large
    steps:
      - checkout
      - install_deps
      - run:
          name: TIMM TorchInductor inference run
          no_output_timeout: 30m
          command: |
            source .circleci/setup_env.sh
            make develop
            python benchmarks/timm_models.py --accuracy --ci -d cuda --inductor --float32 \
              --total-partitions 4 --partition-id 0 --output=inductor_timm_inference_0.csv
      - store_artifacts:
          path: inductor_timm_inference_0.csv
      - run:
          name: TIMM inference result check
          command: |
            source .circleci/setup_env.sh
            python .circleci/check_csv.py -f inductor_timm_inference_0.csv

  inductor_timm_inference_1:
    machine:
      image: ubuntu-2004-cuda-11.4:202110-01
    resource_class: gpu.nvidia.large
    steps:
      - checkout
      - install_deps
      - run:
          name: TIMM TorchInductor inference run
          no_output_timeout: 30m
          command: |
            source .circleci/setup_env.sh
            make develop
            python benchmarks/timm_models.py --accuracy --ci -d cuda --inductor --float32 \
              --total-partitions 4 --partition-id 1 --output=inductor_timm_inference_1.csv
      - store_artifacts:
          path: inductor_timm_inference_1.csv
      - run:
          name: TIMM inference result check
          command: |
            source .circleci/setup_env.sh
            python .circleci/check_csv.py -f inductor_timm_inference_1.csv

  inductor_timm_inference_2:
    machine:
      image: ubuntu-2004-cuda-11.4:202110-01
    resource_class: gpu.nvidia.large
    steps:
      - checkout
      - install_deps
      - run:
          name: TIMM TorchInductor inference run
          no_output_timeout: 30m
          command: |
            source .circleci/setup_env.sh
            make develop
            python benchmarks/timm_models.py --accuracy --ci -d cuda --inductor --float32 \
              --total-partitions 4 --partition-id 2 --output=inductor_timm_inference_2.csv
      - store_artifacts:
          path: inductor_timm_inference_2.csv
      - run:
          name: TIMM inference result check
          command: |
            source .circleci/setup_env.sh
            python .circleci/check_csv.py -f inductor_timm_inference_2.csv

  inductor_timm_inference_3:
    machine:
      image: ubuntu-2004-cuda-11.4:202110-01
    resource_class: gpu.nvidia.large
    steps:
      - checkout
      - install_deps
      - run:
          name: TIMM TorchInductor inference run
          no_output_timeout: 30m
          command: |
            source .circleci/setup_env.sh
            make develop
            python benchmarks/timm_models.py --accuracy --ci -d cuda --inductor --float32 \
              --total-partitions 4 --partition-id 3 --output=inductor_timm_inference_3.csv
      - store_artifacts:
          path: inductor_timm_inference_3.csv
      - run:
          name: TIMM inference result check
          command: |
            source .circleci/setup_env.sh
            python .circleci/check_csv.py -f inductor_timm_inference_3.csv

  inductor_timm_training_0:
    machine:
      image: ubuntu-2004-cuda-11.4:202110-01
    resource_class: gpu.nvidia.large
    steps:
      - checkout
      - install_deps
      - run:
          name: TIMM TorchInductor training run
          no_output_timeout: 30m
          command: |
            source .circleci/setup_env.sh
            make develop
            python benchmarks/timm_models.py --accuracy --ci -d cuda --inductor --float32 --training \
              --total-partitions 6 --partition-id 0 --output=inductor_timm_training_0.csv
      - store_artifacts:
          path: inductor_timm_training_0.csv
      - run:
          name: TIMM training result check
          command: |
            source .circleci/setup_env.sh
            python .circleci/check_csv.py -f inductor_timm_training_0.csv

  inductor_timm_training_1:
    machine:
      image: ubuntu-2004-cuda-11.4:202110-01
    resource_class: gpu.nvidia.large
    steps:
      - checkout
      - install_deps
      - run:
          name: TIMM TorchInductor training run
          no_output_timeout: 30m
          command: |
            source .circleci/setup_env.sh
            make develop
            python benchmarks/timm_models.py --accuracy --ci -d cuda --inductor --float32 --training \
              --total-partitions 6 --partition-id 1 --output=inductor_timm_training_1.csv
      - store_artifacts:
          path: inductor_timm_training_1.csv
      - run:
          name: TIMM training result check
          command: |
            source .circleci/setup_env.sh
            python .circleci/check_csv.py -f inductor_timm_training_1.csv

  inductor_timm_training_2:
    machine:
      image: ubuntu-2004-cuda-11.4:202110-01
    resource_class: gpu.nvidia.large
    steps:
      - checkout
      - install_deps
      - run:
          name: TIMM TorchInductor training run
          no_output_timeout: 30m
          command: |
            source .circleci/setup_env.sh
            make develop
            python benchmarks/timm_models.py --accuracy --ci -d cuda --inductor --float32 --training \
              --total-partitions 6 --partition-id 2 --output=inductor_timm_training_2.csv
      - store_artifacts:
          path: inductor_timm_training_2.csv
      - run:
          name: TIMM training result check
          command: |
            source .circleci/setup_env.sh
            python .circleci/check_csv.py -f inductor_timm_training_2.csv

  inductor_timm_training_3:
    machine:
      image: ubuntu-2004-cuda-11.4:202110-01
    resource_class: gpu.nvidia.large
    steps:
      - checkout
      - install_deps
      - run:
          name: TIMM TorchInductor training run
          no_output_timeout: 30m
          command: |
            source .circleci/setup_env.sh
            make develop
            python benchmarks/timm_models.py --accuracy --ci -d cuda --inductor --float32 --training \
              --total-partitions 6 --partition-id 3 --output=inductor_timm_training_3.csv
      - store_artifacts:
          path: inductor_timm_training_3.csv
      - run:
          name: TIMM training result check
          command: |
            source .circleci/setup_env.sh
            python .circleci/check_csv.py -f inductor_timm_training_3.csv


  inductor_timm_training_4:
    machine:
      image: ubuntu-2004-cuda-11.4:202110-01
    resource_class: gpu.nvidia.large
    steps:
      - checkout
      - install_deps
      - run:
          name: TIMM TorchInductor training run
          no_output_timeout: 30m
          command: |
            source .circleci/setup_env.sh
            make develop
            python benchmarks/timm_models.py --accuracy --ci -d cuda --inductor --float32 --training \
              --total-partitions 6 --partition-id 4 --output=inductor_timm_training_4.csv
      - store_artifacts:
          path: inductor_timm_training_4.csv
      - run:
          name: TIMM training result check
          command: |
            source .circleci/setup_env.sh
            python .circleci/check_csv.py -f inductor_timm_training_4.csv

  inductor_timm_training_5:
    machine:
      image: ubuntu-2004-cuda-11.4:202110-01
    resource_class: gpu.nvidia.large
    steps:
      - checkout
      - install_deps
      - run:
          name: TIMM TorchInductor training run
          no_output_timeout: 30m
          command: |
            source .circleci/setup_env.sh
            make develop
            python benchmarks/timm_models.py --accuracy --ci -d cuda --inductor --float32 --training \
              --total-partitions 6 --partition-id 5 --output=inductor_timm_training_5.csv
      - store_artifacts:
          path: inductor_timm_training_5.csv
      - run:
          name: TIMM training result check
          command: |
            source .circleci/setup_env.sh
            python .circleci/check_csv.py -f inductor_timm_training_5.csv

workflows:
  gpu:
    jobs:
      - unit_test
      - coverage
      - aot_eager_hf_inference
      - aot_eager_hf_training
      - aot_eager_timm_inference
      - aot_eager_timm_training
      - aot_eager_torchbench_training
      - aot_eager_torchbench_inference
      - inductor_hf_inference_0
      - inductor_hf_inference_1
      - inductor_hf_training_0
      - inductor_hf_training_1
      - inductor_hf_training_2
      - inductor_timm_inference_0
      - inductor_timm_inference_1
      - inductor_timm_inference_2
      - inductor_timm_inference_3
      - inductor_timm_training_0
      - inductor_timm_training_1
      - inductor_timm_training_2
      - inductor_timm_training_3
      - inductor_timm_training_4
      - inductor_timm_training_5
      - inductor_torchbench_inference
      - inductor_torchbench_training_0
      - inductor_torchbench_training_1
